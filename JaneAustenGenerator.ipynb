{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JaneAustenGenerator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmuFvS/0ZTQcDLoo+hKT4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilgupta1093/JaneAustenGenerator/blob/master/JaneAustenGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euT95LGxnu7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0732d87-d128-4599-f7c4-c450e2784946"
      },
      "source": [
        "# All import statements\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuw8Fcv7ZS2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "274dfa58-59b7-45eb-8fdd-55faf6643b38"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inJ0hMg5rsaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fa6b02fa-8ad1-468e-fe9f-c1ce3c10022f"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMhQZ34NrFdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsOXDr4YsDnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load text and convert to lowercase\n",
        "filename = \"/content/drive/My Drive/prideprejudice.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tl8ctYJsTmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5333f369-aa8a-4e3b-ef67-69efa34489ec"
      },
      "source": [
        "# create mapping of unique chars to ints\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total chars:\", n_chars)\n",
        "print(\"Total vocab:\", n_vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total chars: 756216\n",
            "Total vocab: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToZKXddHVCdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "008cb13c-a613-4d2f-c063-3b3a5e9ea7f0"
      },
      "source": [
        "# Prepare the dataset\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns:\", n_patterns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: 756116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LtcbYJaV0qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape X to be [samples, time steps, features] as is needed for LSTM\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# Normalize\n",
        "X = X / float(n_vocab)\n",
        "# One hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__tTFfAKXEoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add( LSTM(256, input_shape=(X.shape[1], X.shape[2])) )\n",
        "model.add( Dropout(0.2) )\n",
        "model.add( Dense(y.shape[1], activation='softmax') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7g__s4dXmjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIXF_hIAXrPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint\n",
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HqHAjZuYJUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7931573a-2778-4514-e7c7-c570f69fb0c9"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "756116/756116 [==============================] - 893s 1ms/step - loss: 2.5805\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.58047, saving model to weights-improvement-01-2.5805.hdf5\n",
            "Epoch 2/20\n",
            "756116/756116 [==============================] - 885s 1ms/step - loss: 2.3771\n",
            "\n",
            "Epoch 00002: loss improved from 2.58047 to 2.37708, saving model to weights-improvement-02-2.3771.hdf5\n",
            "Epoch 3/20\n",
            "756116/756116 [==============================] - 883s 1ms/step - loss: 2.2507\n",
            "\n",
            "Epoch 00003: loss improved from 2.37708 to 2.25075, saving model to weights-improvement-03-2.2507.hdf5\n",
            "Epoch 4/20\n",
            "756116/756116 [==============================] - 878s 1ms/step - loss: 2.1464\n",
            "\n",
            "Epoch 00004: loss improved from 2.25075 to 2.14644, saving model to weights-improvement-04-2.1464.hdf5\n",
            "Epoch 5/20\n",
            "756116/756116 [==============================] - 877s 1ms/step - loss: 2.0620\n",
            "\n",
            "Epoch 00005: loss improved from 2.14644 to 2.06201, saving model to weights-improvement-05-2.0620.hdf5\n",
            "Epoch 6/20\n",
            "756116/756116 [==============================] - 873s 1ms/step - loss: 1.9940\n",
            "\n",
            "Epoch 00006: loss improved from 2.06201 to 1.99401, saving model to weights-improvement-06-1.9940.hdf5\n",
            "Epoch 7/20\n",
            "756116/756116 [==============================] - 885s 1ms/step - loss: 1.9378\n",
            "\n",
            "Epoch 00007: loss improved from 1.99401 to 1.93783, saving model to weights-improvement-07-1.9378.hdf5\n",
            "Epoch 8/20\n",
            "756116/756116 [==============================] - 887s 1ms/step - loss: 1.8925\n",
            "\n",
            "Epoch 00008: loss improved from 1.93783 to 1.89254, saving model to weights-improvement-08-1.8925.hdf5\n",
            "Epoch 9/20\n",
            "756116/756116 [==============================] - 897s 1ms/step - loss: 1.8543\n",
            "\n",
            "Epoch 00009: loss improved from 1.89254 to 1.85429, saving model to weights-improvement-09-1.8543.hdf5\n",
            "Epoch 10/20\n",
            "756116/756116 [==============================] - 902s 1ms/step - loss: 1.8226\n",
            "\n",
            "Epoch 00010: loss improved from 1.85429 to 1.82259, saving model to weights-improvement-10-1.8226.hdf5\n",
            "Epoch 11/20\n",
            "756116/756116 [==============================] - 905s 1ms/step - loss: 1.7959\n",
            "\n",
            "Epoch 00011: loss improved from 1.82259 to 1.79591, saving model to weights-improvement-11-1.7959.hdf5\n",
            "Epoch 12/20\n",
            "756116/756116 [==============================] - 875s 1ms/step - loss: 1.7741\n",
            "\n",
            "Epoch 00012: loss improved from 1.79591 to 1.77413, saving model to weights-improvement-12-1.7741.hdf5\n",
            "Epoch 13/20\n",
            "756116/756116 [==============================] - 883s 1ms/step - loss: 1.7581\n",
            "\n",
            "Epoch 00013: loss improved from 1.77413 to 1.75807, saving model to weights-improvement-13-1.7581.hdf5\n",
            "Epoch 14/20\n",
            "756116/756116 [==============================] - 881s 1ms/step - loss: 1.7391\n",
            "\n",
            "Epoch 00014: loss improved from 1.75807 to 1.73908, saving model to weights-improvement-14-1.7391.hdf5\n",
            "Epoch 15/20\n",
            "756116/756116 [==============================] - 880s 1ms/step - loss: 1.7236\n",
            "\n",
            "Epoch 00015: loss improved from 1.73908 to 1.72363, saving model to weights-improvement-15-1.7236.hdf5\n",
            "Epoch 16/20\n",
            "756116/756116 [==============================] - 875s 1ms/step - loss: 1.7060\n",
            "\n",
            "Epoch 00016: loss improved from 1.72363 to 1.70604, saving model to weights-improvement-16-1.7060.hdf5\n",
            "Epoch 17/20\n",
            "756116/756116 [==============================] - 876s 1ms/step - loss: 1.6928\n",
            "\n",
            "Epoch 00017: loss improved from 1.70604 to 1.69284, saving model to weights-improvement-17-1.6928.hdf5\n",
            "Epoch 18/20\n",
            "756116/756116 [==============================] - 877s 1ms/step - loss: 1.6792\n",
            "\n",
            "Epoch 00018: loss improved from 1.69284 to 1.67920, saving model to weights-improvement-18-1.6792.hdf5\n",
            "Epoch 19/20\n",
            "756116/756116 [==============================] - 875s 1ms/step - loss: 1.6659\n",
            "\n",
            "Epoch 00019: loss improved from 1.67920 to 1.66592, saving model to weights-improvement-19-1.6659.hdf5\n",
            "Epoch 20/20\n",
            "756116/756116 [==============================] - 873s 1ms/step - loss: 1.6592\n",
            "\n",
            "Epoch 00020: loss improved from 1.66592 to 1.65924, saving model to weights-improvement-20-1.6592.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f9f7ecfb4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLjQT4kdYWZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the network weights\n",
        "filename = \"weights-improvement-20-1.6592.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNrOYyROhus0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make reverse mapping\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXHqElm2iBPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2aff59cf-a012-4cd4-8c17-35f688448a33"
      },
      "source": [
        "# Pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" \n",
            "\n",
            "      the colour which had been driven from her face, returned for half\n",
            "      a minute with an add \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONXdp7gsikaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "52433f19-31be-4e06-fd27-dabdb2d983b6"
      },
      "source": [
        "# Generate characters\n",
        "import sys\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ersence of the sooe the same tooe the was to\n",
            "      see mote than the sooe of the sooe the sase of the sooe thet\n",
            "      seruind to the person the same tooe the same tooe the was of\n",
            "      seeeng the same tooe the same tooe the same tooe the was oo\n",
            "      sereruly oo the sooe the sare of the sooe the same tooe the\n",
            "      consersance of the poom of the sooe the same tooe the was to\n",
            "      shete that her faal of the sooe whse to be iose the seme of the\n",
            "      consersanion of the sooe the same tooe the same tooe the same\n",
            "      connestion of the poom of the sooe the sase of the sooe thet\n",
            "      sereruly to the person the sase of the sooe the same tooe the\n",
            "      consersanco of the sooe the sase of the sooe the same tooe the\n",
            "      consersanco of the sooe the sase of the sooe the same tooe the\n",
            "      consersanco of the sooe the sase of the sooe the same tooe the\n",
            "      consersanco of the sooe the sase of the sooe the same tooe the\n",
            "      consersanco of the sooe the sase of the sooe the same tooe the\n",
            "    \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}